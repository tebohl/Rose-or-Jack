{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83977a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd53ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_train = pd.read_excel('Resources/titanic_full.xls')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01080318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted columns\n",
    "df_train.drop([\"name\",\"ticket\",\"cabin\",\"home.dest\",\"body\",\"boat\",\"embarked\"], axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f569f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting Pclass column to strings\n",
    "df_train['pclass'] = df_train['pclass'].replace([1,2,3],['1st','2nd','3rd'])\n",
    "df_train['family'] = df_train['sibsp']+df_train['parch']\n",
    "df_train.drop(['sibsp','parch'], axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba87072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if any fare points are outside of the 1.5*IQR range (outliers)\n",
    "amounts = df_train['fare'].sort_values()\n",
    "quartiles = np.quantile(amounts,[.25,.75])\n",
    "iqr = quartiles[1]-quartiles[0]\n",
    "lower_bound = quartiles[0]-(1.5*iqr)\n",
    "upper_bound = quartiles[1]+(1.5*iqr)\n",
    "\n",
    "potential_outliers = [print(amt) if amt < lower_bound or amt > upper_bound else next for amt in amounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NAN Values\n",
    "df_train = df_train.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data to dummy values for testing\n",
    "df_train = pd.get_dummies(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e24c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "y = df_train[\"survived\"].values\n",
    "X = df_train.drop(\"survived\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e29df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf97bb6",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model print the model score\n",
    "classifier = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05806542",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f753f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 5 provides the best accuracy where the classifier starts to stablize\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=11 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012a2a4",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf24748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes\n",
    "# for each layer.\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=40, activation=\"relu\", input_dim=8))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=20, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=20, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dadfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9dcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01c597",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a15a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "X, y = make_classification(random_state=1, n_features=8, n_informative=5, n_redundant=0)\n",
    "X = pd.DataFrame(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = clf.feature_importances_\n",
    "print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a80c7f",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf, open('model_randomforrest_2022080848.pkl','wb'))\n",
    "# save the scaler\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData38] *",
   "language": "python",
   "name": "conda-env-PythonData38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
